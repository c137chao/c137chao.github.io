<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tinykv on Summer Blog Space</title>
    <link>http://c137chao.github.io/categories/tinykv/</link>
    <description>Recent content in tinykv on Summer Blog Space</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://c137chao.github.io/categories/tinykv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>tinykv lab2c snapshot</title>
      <link>http://c137chao.github.io/blog/tinykv-lab2c/</link>
      <pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>http://c137chao.github.io/blog/tinykv-lab2c/</guid>
      <description>指导书传送门 结合官方解读食用 TiKV 源码解析系列文章（十）Snapshot 的发送和接收 | PingCAP 不妨尝试调试一下 snapshot 的测试部分去理解该过程
When SnapShot peerMsgHandler会定期进行RaftLogGC检查，收到 PeerTickRaftLogGC 以后会判断 Leader 当前日志是否可以压缩（持有一定数量的已经被apply的logEntry），如果达到需要压缩的数量会产生一个 CompactLog 请求去处理。
func (d *peerMsgHandler) onRaftGCLogTick() { d.ticker.schedule(PeerTickRaftLogGC) if !d.IsLeader() { return } // if no enougth log -&amp;gt; return  // else compactIdx = appliedIdx - 1, why - 1 ????  // ...  term, err := d.RaftGroup.Raft.RaftLog.Term(compactIdx) // check err  // Create a compact log request and notify directly.  regionID := d.</description>
    </item>
    
    <item>
      <title>tinykv lab2b kvraft</title>
      <link>http://c137chao.github.io/blog/tinykv-lab2b/</link>
      <pubDate>Thu, 14 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>http://c137chao.github.io/blog/tinykv-lab2b/</guid>
      <description>指导书传送门 涉及代码比较多，结合源码系列食用效果更佳 TiKV 源码解析系列 - multi-raft 设计与实现 总览 存储大文件时会将该文件切分成小的Shard分别存储，为了保证高可用性，每个Shard会存储到多个节点(节点是一个逻辑概念，一台服务器可对应多个节点)上，通过 Raft 协议保证数据的一致，节点对应指导书中的 Peer，这样一组节点称为 Raft Group 或者 Region。
数据切片应选择对应的 Region 存放，最粗暴的方法是使用 Hash Sharding (在6.824的lab4中使用的方法)，但 Hash 方法在数据规模增长，服务器扩充以后产生大量的数据迁移， tinykv 使用 range sharding，每个 region 维护一个区间[start_key, end_key]，上层请求根据携带的 Key 到对应的 Region 中去执行 。 请求执行过程 收到上层发送的请求以后(Put/Delete/Get/Scan)，Cluster 首先会根据 key 通过找到其所在的 Region，然后找到该 Region 的 Leader，将请求发送给 Leader 等待对方回复。
// cluster:Request region := c.GetRegion(key) regionID := region.GetId() req := NewRequest(regionID, region.RegionEpoch, reqs) resp, txn := c.CallCommandOnLeader(&amp;amp;req, timeout) // ....  所有的 Region 存储在BTree上，根据 StartKey 来排序，GetRegion(key) 最终会调用 findRegion(key)，找到最后一个StartKey &amp;lt;= key 的 Region</description>
    </item>
    
    <item>
      <title>tinykv lab2a raft</title>
      <link>http://c137chao.github.io/blog/tinykv-lab2a/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>http://c137chao.github.io/blog/tinykv-lab2a/</guid>
      <description>指导书传送门Raft小论文传送门
Raft 被分为 3 个部分 rawnode.go，raft.go，log.go
 log.go: 底层日志的管理、存储、压缩 raft.go: 一个 FSM, 推进节点状态的改变 rawnode.go: 与上层的接口，peer 通过 rawnode 驱动 raft 的工作  1. Part-A Raft-Basic(2aa) 1.1 raft election 简介 节点最开始都是Follower，某个或者某些节点发生 election timeout，该节点将发起选举投票 关于 election 详细描述在Raft小论文5.2节和5.4节
选举过程： 除论文中描述的选举过程，Tinykv 中规定 Candidate 需要额外再做一件事：收到半数拒绝则恢复为 Follower，而不是维持 Candidate，原因暂时不详。
来自6.824的经验：如果消息是并行处理，那RaftPeer在发送消息的过程中可能因为接收到其他消息改变了自身的 State，Term 等信息（往往是发现因自己任期过旧或者日志落后而出现降级 Leader -&amp;gt; Follower，Candidate -&amp;gt; Follower），这时该节点无论是在发起选举还是发送 Log Entries，都应及时察觉到自己的状态已经发生改变，而不是把旧状态选举的结果应用到新的任期中去。
投票规则 关于 up-to-date 在 论文5.4.1最后有提到：
 If the logs have last entries with different terms, then the log with the later term is more up-to-date.</description>
    </item>
    
    <item>
      <title>tinykv lab3</title>
      <link>http://c137chao.github.io/blog/tinykv-lab3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://c137chao.github.io/blog/tinykv-lab3/</guid>
      <description>3A纯纯的面向测试编程，基本要求阅读指导书即可 3B需要多阅读代码，主要在于明确confChange和SplitRegion的整个流程 3C跟着指导书的步骤完成，再通过测试调试即可
1. TransferLead Note:
 MsgTransferLeader 是需要 CallBack 的，在把这条请求 propose 到 Raft 节点之后就可以 CallBack，因为 TransferLead 是不会 apply 的 TransferLead 如果发现对方not Up-to-date，就会 sendAppend 给对方，这种情况下，可以在收到对方的 AppendResponse 以后判断一下对方是否是我的 LeadTransFee，如果是并且对方已经确认了我的所有 Log Entry 就发送一条 MsgTimeOutNow 给对方，还有很多其他策略，主要利用好 LeadTranFee 如果 Leader 刚收到 TransferLead 给其他 raft 节点之后又收到重新将 Leader 转移给自己，直接将自己的 Term 加2即可，这样对方会因为任期小于自己而选举失败，没有必要让 Leader 也重新发起投票 LeaderTranfer 的时候不会接受任何日志，完成3C可以知道如果某个Store上面的Region太多，负载比较大，如果把该 Store 上的某个Region的Leader移动到其他负载较小的Store上去，中间可能带有 TransferLead 操作，而这时候因为原本Leader所在的Store处理请求的压力已经很大了，所以应该优先完成 LeaderTransfer  2.ConfChange 关于 ConfChangePending
Only one conf change may be pending (in the log, but not yet applied) at a time.</description>
    </item>
    
  </channel>
</rss>
